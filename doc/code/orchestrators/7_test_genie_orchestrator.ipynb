{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d425ce",
   "metadata": {},
   "source": [
    "# TestGenie Orchestrator: Step-by-Step Workflow\n",
    "\n",
    "This notebook demonstrates a clean, step-by-step TestGenie workflow. Each cell represents one step in the pipeline, making it easy to understand, modify, and re-run individual steps.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Setup & Initialize**: Import libraries and create orchestrator\n",
    "2. **Extract Claims**: Convert problematic utterance to testable claims\n",
    "3. **Select Claim**: Choose one claim to work with\n",
    "4. **Generate Inferences**: Create related inferences from the claim\n",
    "5. **Generate Tests**: Create test prompts from inferences\n",
    "6. **Review Results**: Examine and export results\n",
    "\n",
    "## Usage\n",
    "\n",
    "- Run cells sequentially from top to bottom\n",
    "- Each cell builds on the previous step's results\n",
    "- Modify parameters in any cell and re-run to experiment\n",
    "- State is maintained in simple variables between cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bf3dc",
   "metadata": {},
   "source": [
    "## Step 0: Setup and Initialize Orchestrator\n",
    "\n",
    "Import required libraries and set up the TestGenie orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9101eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73431beeae0445f68d6282eed4dca0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961161a93dca4139888f8972c1c51fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/130899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0185b6f00d9b4270b6550d86c8e231be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e375a168fc444757886fe41626fe4f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/34791 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd425211b99442196bb705403adfd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8464731acf4458e8dc7377c6b9e3b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TestGenie Orchestrator initialized!\n",
      "ğŸ†” Workflow ID: 0620a675-a7c0-40cb-a74d-70dace39403d\n",
      "â° Started at: 07:47:40\n",
      "\n",
      "â¡ï¸  Next: Run Step 1 to extract claims\n",
      "\n",
      "ğŸ”§ Note: Interactive orchestrator with real async methods imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import uuid\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import importlib\n",
    "\n",
    "# PyRIT imports\n",
    "from pyrit.memory import DuckDBMemory, CentralMemory\n",
    "from pyrit.prompt_target import OpenAICompletionTarget\n",
    "from pyrit.common import default_values\n",
    "\n",
    "# Reload the module to get the latest changes\n",
    "import pyrit.orchestrator.test_genie_orchestrator\n",
    "importlib.reload(pyrit.orchestrator.test_genie_orchestrator)\n",
    "from pyrit.orchestrator.test_genie_orchestrator import TestGenieOrchestrator\n",
    "\n",
    "# Initialize environment\n",
    "default_values.load_environment_files()\n",
    "CentralMemory.set_memory_instance(DuckDBMemory())\n",
    "\n",
    "# Create enhanced orchestrator with UI capabilities\n",
    "target = OpenAICompletionTarget(is_azure_target=False)\n",
    "orchestrator = TestGenieOrchestrator(prompt_target=target)\n",
    "\n",
    "# Initialize workflow variables\n",
    "workflow_id = str(uuid.uuid4())\n",
    "start_time = datetime.now()\n",
    "\n",
    "print(f\"âœ… TestGenie Orchestrator initialized!\")\n",
    "print(f\"ğŸ†” Workflow ID: {workflow_id}\")\n",
    "print(f\"â° Started at: {start_time.strftime('%H:%M:%S')}\")\n",
    "print(\"\\nâ¡ï¸  Next: Run Step 1 to extract claims\")\n",
    "print(\"\\nğŸ”§ Note: Interactive orchestrator with real async methods imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549fcecb",
   "metadata": {},
   "source": [
    "## Step 1: Extract Claims from Utterance\n",
    "\n",
    "Analyze a problematic utterance and extract testable claims from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b99f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Using provided utterance: He should stay inside. Since he has cancer, if he goes outside someone could get it.\n",
      "ğŸ”„ Extracting claims...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Extracted 5 claims:\n",
      "   1. Cancer patients are dangeroushe --> cancer patients are dangerous\n",
      "   2. People with cancer should not leave their homes.\n",
      "   3. People with cancer should be isolated\n",
      "   4. People with cancer should not interact with others\n",
      "   5. People with cancer pose a health risk\n",
      "\n",
      "ğŸ“Š Found 5 testable claims\n",
      "\n",
      "â¡ï¸  Next: Run Step 2 to select a claim\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract claims with interactive input\n",
    "# Test the actual method now that async is working\n",
    "claims = orchestrator.extract_claims_interactive(\"He should stay inside. Since he has cancer, if he goes outside someone could get it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08064d52",
   "metadata": {},
   "source": [
    "## Step 2: Select Claim to Work With\n",
    "\n",
    "Choose one of the extracted claims for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862e57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ec8ab8bcf141ae8182167d6265016d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Select a claim to work with (5 available):</h4>'), Dropdown(description='Selectâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘† Select a claim and click 'Confirm Selection' above to proceed\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Select claim with interactive dropdown\n",
    "claims = orchestrator.select_claim_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f5858",
   "metadata": {},
   "source": [
    "## Step 3: Generate Inferences\n",
    "\n",
    "Generate related inferences from the selected claim using different reasoning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9839d305c34b319a336595791ce999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Generate inferences for: <em>People with cancer should be isolated</em></h4>'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘† Configure settings and click 'Generate Inferences' above to proceed\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Generate inferences with interactive configuration\n",
    "inferences = orchestrator.generate_inferences_interactive(max_inferences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad7cb3",
   "metadata": {},
   "source": [
    "## Step 4: Generate Test Prompts\n",
    "\n",
    "Create test prompts from the generated inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a713e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6533144bb0e84c3cb4f84105600d728f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Select inferences to generate tests from:</h4>'), SelectMultiple(description='Iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘† Configure settings and click 'Generate Tests' above to proceed\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Generate test prompts with interactive selection\n",
    "all_tests = orchestrator.generate_tests_interactive(tests_per_inference=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499ea69",
   "metadata": {},
   "source": [
    "## Step 5: Review Results and Export\n",
    "\n",
    "Review the complete pipeline results and export data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06f103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ TestGenie Pipeline Complete!\n",
      "==================================================\n",
      "ğŸ†” Workflow ID: 0620a675-a7c0-40cb-a74d-70dace39403d\n",
      "â° Duration: 0:00:23\n",
      "ğŸ“ Original utterance: He should stay inside. Since he has cancer, if he goes outside someone could get it.\n",
      "ğŸ“Š Claims extracted: 5\n",
      "ğŸ¯ Selected claim: People with cancer should be isolated\n",
      "ğŸ§  Inferences generated: 3\n",
      "ğŸ§ª Test prompts created: 6\n",
      "ğŸ“‹ Detailed Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ebfa1eb7a84a2ca8799dff63b61b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output(), Output()), selected_index=0, titles=('Claims (5)', 'Inferences (3)', 'Tests â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ Pipeline completed successfully!\n",
      "ğŸ”„ To run again: Restart kernel and run all cells, or modify parameters and re-run specific steps.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Review results and export\n",
    "# Get comprehensive workflow data from orchestrator\n",
    "workflow_data = orchestrator.get_workflow_summary()\n",
    "\n",
    "# Calculate workflow statistics\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "# Create comprehensive summary\n",
    "summary = {\n",
    "    'workflow_id': workflow_id,\n",
    "    'timestamp': end_time.isoformat(),\n",
    "    'duration_seconds': duration.total_seconds(),\n",
    "    'original_utterance': workflow_data['utterance'],\n",
    "    'total_claims_extracted': len(workflow_data['claims']),\n",
    "    'selected_claim': workflow_data['selected_claim'],\n",
    "    'selected_claim_index': workflow_data['selected_claim_index'],\n",
    "    'total_inferences_generated': len(workflow_data['inferences']),\n",
    "    'inferences_used_for_tests': len(workflow_data['selected_inferences']),\n",
    "    'tests_per_inference': workflow_data['tests_per_inference'],\n",
    "    'total_test_prompts': len(workflow_data['all_tests']),\n",
    "    'claims': workflow_data['claims'],\n",
    "    'inferences': workflow_data['inferences'],\n",
    "    'test_prompts': workflow_data['all_tests']\n",
    "}\n",
    "\n",
    "# Display summary\n",
    "print(\"ğŸ‰ TestGenie Pipeline Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ†” Workflow ID: {workflow_id}\")\n",
    "print(f\"â° Duration: {str(duration).split('.')[0]}\")\n",
    "print(f\"ğŸ“ Original utterance: {workflow_data['utterance']}\")\n",
    "print(f\"ğŸ“Š Claims extracted: {len(workflow_data['claims'])}\")\n",
    "print(f\"ğŸ¯ Selected claim: {workflow_data['selected_claim']}\")\n",
    "print(f\"ğŸ§  Inferences generated: {len(workflow_data['inferences'])}\")\n",
    "print(f\"ğŸ§ª Test prompts created: {len(workflow_data['all_tests'])}\")\n",
    "\n",
    "# Display detailed results in tabs\n",
    "print(\"ğŸ“‹ Detailed Results:\")\n",
    "\n",
    "# Create tabs for different result types\n",
    "claims_output = widgets.Output()\n",
    "inferences_output = widgets.Output()\n",
    "tests_output = widgets.Output()\n",
    "\n",
    "# Fill claims tab\n",
    "with claims_output:\n",
    "    print(f\"All Extracted Claims ({len(workflow_data['claims'])} total):\\n\")\n",
    "    for i, claim in enumerate(workflow_data['claims'], 1):\n",
    "        marker = \"ğŸ‘‰\" if i-1 == workflow_data['selected_claim_index'] else \"  \"\n",
    "        print(f\"{marker} {i}. {claim}\")\n",
    "\n",
    "# Fill inferences tab\n",
    "with inferences_output:\n",
    "    print(f\"Generated Inferences ({len(workflow_data['inferences'])} total):\\n\")\n",
    "    for i, inference in enumerate(workflow_data['inferences'], 1):\n",
    "        print(f\"{i}. {inference}\\n\")\n",
    "\n",
    "# Fill tests tab\n",
    "with tests_output:\n",
    "    print(f\"Generated Test Prompts ({len(workflow_data['all_tests'])} total):\\n\")\n",
    "    for i, test in enumerate(workflow_data['all_tests'], 1):\n",
    "        print(f\"{i}. {test}\\n\")\n",
    "        print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "# Display tabs\n",
    "tab = widgets.Tab(children=[claims_output, inferences_output, tests_output])\n",
    "tab.set_title(0, f\"Claims ({len(workflow_data['claims'])})\")\n",
    "tab.set_title(1, f\"Inferences ({len(workflow_data['inferences'])})\")\n",
    "tab.set_title(2, f\"Tests ({len(workflow_data['all_tests'])})\")\n",
    "\n",
    "display(tab)\n",
    "\n",
    "print(f\"ğŸ Pipeline completed successfully!\")\n",
    "print(f\"ğŸ”„ To run again: Restart kernel and run all cells, or modify parameters and re-run specific steps.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrit-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
